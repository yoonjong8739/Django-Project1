{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca4b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome(\"C:\\\\Users\\\\iris8\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "driver2 = webdriver.Chrome(\"C:\\\\Users\\\\iris8\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
    "\n",
    "\n",
    "driver.get(\"https://ebook.kyobobook.co.kr/dig/pnd/showcase?pageNo=323&cmdt=EBK&clst1=01&clst2=&clst3=&landing=Y\")\n",
    "\n",
    "\n",
    "# 카테고리 추출\n",
    "driver.find_elements(By.CSS_SELECTOR, '.btn_sub_depth')[1].click()\n",
    "time.sleep(2)\n",
    "datas = driver.find_elements(By.CSS_SELECTOR, '.sub_depth_box')\n",
    "\n",
    "\n",
    "categories = []\n",
    "\n",
    "for data in datas :\n",
    "    li = data.find_elements(By.CSS_SELECTOR, '.sub_depth_list a')\n",
    "    for i in range(len(li)) :\n",
    "        if li[i].text != '' and li[i].text != '섹슈얼로맨스' and li[i].text != '웹툰' and li[i].text != '로맨스' and li[i].text != 'BL':\n",
    "            categories.append(li[i].text)\n",
    "\n",
    "# for i in range(len(categories)) :\n",
    "#     print(categories[i])\n",
    "\n",
    "# 이어서 하기\n",
    "categories = categories[17:]\n",
    "\n",
    "\n",
    "# 카테고리 별\n",
    "for category in categories :\n",
    "    # print(category)\n",
    "    isbns = []\n",
    "    fields = []\n",
    "    books = []\n",
    "    driver.find_elements(By.CSS_SELECTOR, '.btn_sub_depth')[1].click()\n",
    "    time.sleep(2)\n",
    "    driver.find_element(By.LINK_TEXT, category).click()\n",
    "\n",
    "\n",
    "    # 10페이지 씩\n",
    "    for i in range(11) :\n",
    "        time.sleep(2)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        data = soup.select('.prodDt_detail')\n",
    "        contents = driver.find_elements(By.CSS_SELECTOR, '.prodDt')\n",
    "\n",
    "        # 상세페이지 주소를 통한 isbn & 카테고리\n",
    "        for link in data :\n",
    "            try :\n",
    "                detail = link.select_one('strong h3 a').attrs['href']\n",
    "                driver2.get(detail)\n",
    "                time.sleep(2)\n",
    "                isbn = driver2.find_elements(By.CSS_SELECTOR, '.prod_pordInfo_box em')[1].text\n",
    "                field = driver2.find_element(By.CSS_SELECTOR, '.intro_category_link').text\n",
    "                isbns.append(isbn)\n",
    "                fields.append(field)\n",
    "            except :\n",
    "                isbns.append('0000000000000')\n",
    "                fields.append(category)\n",
    "\n",
    "        # 전체 목록에서 그 외 정보 추출\n",
    "        for content in contents :\n",
    "            try :\n",
    "                img = content.find_element(By.CSS_SELECTOR, '.prodDt_cover img').get_attribute('src')\n",
    "            except :\n",
    "                img = ''\n",
    "            \n",
    "            try :\n",
    "                title = content.find_element(By.CSS_SELECTOR, '.prodDt_detail strong h3').text\n",
    "            except:    \n",
    "                title = ''\n",
    "            \n",
    "            try: \n",
    "                author = content.find_element(By.CSS_SELECTOR, '.prodDt_detail .prodDt_info').text.split(' ')[0]\n",
    "            except:\n",
    "                author = ''\n",
    "            \n",
    "            try :\n",
    "                price = content.find_element(By.CSS_SELECTOR, '.prodDt_detail .prodDt_price b').text\n",
    "            except :\n",
    "                price = '0'\n",
    "            \n",
    "            try :\n",
    "                star = content.find_element(By.CSS_SELECTOR, '.prodDt_detail .prodDt_review b').text\n",
    "            except:\n",
    "                star = \"0.0\"\n",
    "\n",
    "            price = price.replace(',', '')\n",
    "            books.append([title, author, price, star, img])\n",
    "\n",
    "        # 다음 페이지 이동\n",
    "        try :\n",
    "            driver.find_element(By.CSS_SELECTOR, '.btn_page.next').click()\n",
    "        except :\n",
    "            pass\n",
    "        \n",
    "\n",
    "\n",
    "# 데이터 프레임 생성\n",
    "    df = pd.DataFrame(columns=['ISBN', 'title', 'author', 'price', 'star', 'category', 'img'])\n",
    "\n",
    "    for i in range(len(isbns)) :\n",
    "        df.loc[i] = {\n",
    "            \"ISBN\" : isbns[i],\n",
    "            \"title\" : books[i][0],\n",
    "            \"author\" : books[i][1],\n",
    "            \"price\" : int(books[i][2]),\n",
    "            \"star\" : books[i][3],\n",
    "            \"category\" : fields[i],\n",
    "            \"img\" : books[i][4],\n",
    "        }\n",
    "    cat_name = category.replace('/', ',')\n",
    "    df.to_csv('./res/'+cat_name+'.csv', index=False, encoding='cp949')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
